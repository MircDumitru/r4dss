# Data transformation {#sec-data-transformation}

```{r}
#| echo: false

source("_settings.R")
```

## Introduction

Visualization is an important tool for generation insight, but it's rare that you get the data in exactly the right form you need to make the graph you want. Often you'll need to create some new variables or summaries to answer you questions with your data, or maybe you just want to rename the variables or reorder the observations to make the data a little easier to work with. You'll learn how to do all that and more in this chapter, which will introduce you to the data transformation using the **dplyr** package and a new data set on flights that departed from New York City in 2013.

The goal of this chapter is to give you an overview of all the key tools for transforming a data frame. We'll start with function that operate on rows and then columns of a data frame, then circle back to talk more about the pipe, an important tool that you use to combine verbs. We will then introduce the ability to work with groups. We will end up the chapter with a case study that showcases these functions in action. In later chapter, we'll return to the function in more detail as we start to dig into specific types of data (e.g. numbers, string, dates).

### Prerequistes

In this chapter we'll focus on the **dplyr** package, another core member of the tidyverse. We'll illustrate the key ideas using data from the **nycflights13** package and use ggplot2 to help us understand the data.

```{r}
library(nycflights13)
library(tidyverse)
```

Take careful note of the conflicts message that's printed when you load the tidyverse. It tells you that dplyr overwrites some functions in base R. If you want to use the base version of these function after loading dplyr, you'll need to use their full names: `stats::filter()` and `stats::lag()`. So far, we've mostly ignored which package a function comes from because it doesn't usually matter. However, knowing the package can help you find help and find related functions, so when we need to be precise about which package a function comes from, we'll use the same syntax as R: `packagename::functionname()`.

### nycflights13

Toe explore the basic dplyr verbs, we will use `nycflights13::flights`. This dataset contains all 336776 flights that departed from New York City in 2013. The data comes from the US [Bureau of Transportation Statistics](https://www.transtats.bts.gov/DL_SelectFields.aspx?gnoyr_VQ=FGJ&QO_fu146_anzr=b0-gvzr) and it's documented in `?flights`.

```{r}
flights
```

`flights` is a tibble, a special type of data frame used by the tidyverse to avoid some common gotchas. The most important difference between tibbles and data frames is the way tibbles print; they are designed for large datasets, so they only show the first few rows and only the columns that fit on one screen. There are a few options to see everything. If you're using RStudio, the most convenient is probably `View(flights)`, which opens an interactive, scrollable and filterable view. Otherwise you can use `print(flights, width = Inf)` to show all columns, or use `glimpse()`:

```{r}
glimpse(flights)
```

In both views, the variable names are followed by abbreviations that tell you the type of each variable: `<int>` is short for integer, `<dbl>` is short for double (aka real numbers), `<chr>` is short for character (aka strings) and `<dttm>` is short for date-time. These are important because the operations you can perform on a column depend heavily on its "type".

### dplyr basics

You're about to learn to primary dplyr verbs (functions), which will allow you to solve the vast majority of your data manipulation challenges. But before we discuss their individual differences, it's worth stating what they have in common:

1.  The first argument is always a data frame.

2.  The subsequent arguments typically describe which columns to operate on using the variable names (without quotes).

3.  The output is always a new data frame.

Because each verb does one thing well, solving complex problems will usually require combining multiple verbs, and we'll do so with pipe, `|>`. We'll discuss the pipe more in @sec-the-pipe, but in brief, the pipe takes the thing on its left and passes it along to the function on its right so that `x |> f(y)` is equivalent to `f(x, y)`, and `x |> f(y) |> g(z)` is equivalent to `g(f(x, y), z)`. The easiest way to pronounce the pipe is "then". That makes it possible to get a sense of the following code even though you haven't yet learned the details:

```{r}
#| eval: false
flights |>
  filter(dest == 'IAH') |>
  group_by(year, month, day) |>
  summarize(
    arr_delay = mean(arr_delay, na.rm = TRUE)
)
```

dplyr's verbs are organized into four groups based on what they operate on: **rows**, **columns**, **groups** or **tables**. In the following sections, you'll learn the most important verbs for rows, columns and groups. Then, we'll return to the join verbs that work on tables in @sec-joins.

## Rows

The most important verbs that operate on rows of a dataset are `filter()`, which changes which rows are present without changing their order, and `arrange()`, which changes the order of the rows without changing which are present. Both functions only affect the rows, and the columns are left unchanged. We'll also discuss `distinct()` which finds rows with unique values. Unlike `arrange()` and `filter()` it can also optionally modify the columns.

### `filter()`

`filter()` allows you to keep rows based on the values of the columns. The first argument is the data frame. The second and subsequent arguments are the conditions that must be true to keep the row. For example, we could find all flights that departed more than 120 minutes (two hours) late:

```{r}
flights |>
  filter(dep_delay > 120)
```

As well as `>` (greater than), you can use `>=` (greater than or equal to), `<` (less than), `<=` (less than or equal to), `==` (equal to), and `!=` (not equal to). You can also combine conditions with `&` or `,` to indicate "and" (check for both conditions) or with `|` to indicate "or" (check for either condition):

```{r}
# Flights that departed on January 1
flights |>
  filter(month == 1, day == 1)
```

```{r}
# Flights that departed in January or February
flights |>
  filter(month == 1 | month == 2)
```

There is a useful shortcut when you're combining `|` and `==`: `%in%`. It keeps rows where the variable equals one of the values on the right:

```{r}
# Flights that departed in January or February
flights |>
  filter(month %in% c(1, 2))
```

We'll come back to these comparisons and logical operators in more detail in @sec-logical-vectors.

When you run `filter()` dplyr executes the filtering operation, creating a new data frame, and then prints it. It doesn't modify the existing `flights` dataset because dplyr functions never modify their inputs. To save the result, you need to use the assignment `<-`:

```{r}
jan1 <- flights |>
  filter(month == 1, day == 1)
```

### Common mistakes

When you're starting out with R, the easiest mistake to make is to use `=` instead of `==` when testing for equality. `filter()` will let you know when this happens.

```{r}
#| error: true
flights |>
  filter(month = 1)
```

Another mistake is you write "or" statements like you would in English:

```{r}
#| eval: false
flights |>
  filter(month == 1 | 2)
```

This "works" in the sense that it doesn't throw an error, but it doesn't do what you want because `|` first checks the condition `month == 1` and then checks the condition `2`, which is not a sensible condition to check. We'll learn more about what's happening here and why in @sec-boolean-algebra.

### `arrange()`

`arange()` changes the order of the rows based on the value of the columns. It takes a data frame and a set of column names (or more complicated expressions) to order by. If you provide more than one column name, each additional column will be used to break ties in the values of the preceding columns.

For example, the following code sorts by the departure time, which is spread over four columns. We get earliest years first, then within a year, the earliest months, etc.

```{r}
flights |>
  arrange(year, month, day, dep_time)
```

You can use `desc()` on a column inside of `arrange()` to re-order the data frame based on that column in descending (big to small) order. For example, this code orders flights from most to least delayed:

```{r}
flights |>
  arrange(desc(dep_delay))
```

Note that the number of rows has not changed - we're only arranging the data we're not filtering it.

### `distinct()`

`distinct()` finds all the unique rows in a dataset, so technically it primarily operates on rows. Most of the time, however, you'll want the distinct combination of some variables, so you can also optionally supply column names:

```{r}
# Remove duplicate rows, if any
flights |>
  distinct()
```

```{r}
# Find all unique origin and destination pairs
flights |>
  distinct(origin, dest)
```

Alternatively, if you want to keep other columns when filtering for unique rows, you can use the `.keep_all = TRUE` option.

```{r}
flights |>
  distinct(origin, dest, .keep_all = TRUE)
```

It's not a coincidence that all of these distinct flights are on January 1: `distinct()` will find the first occurrence of a unique row in the dataset and discard the rest.

If you want to find the number of occurrences instead, you're better of swapping `distinct()` for `count()`. With the `sort = TRUE` argument, you can arrange them in descending order of the number of occurrences. You will learn more about count in @sec-counts.

```{r}
flights |>
  count(origin, dest, sort = TRUE)
```

Using `count()` with `sort = TRUE` and then `arrange()` will arrange them in ascending order.

```{r}
flights |>
  count(origin, dest, sort = TRUE) |>
  arrange(n)
```

### Exercises

1.  In a single pipeline for each condition find all flights that meet the condition:

    -   Had an arrival delay of two or more hours.

        ```{r}
        # The flights that had an arrival delay of two or more hours (120 minutes)
        flights |>
          filter(arr_delay > 120) 
        ```

    -   Flew to Huston (`IAH` or `HOU`).

        ```{r}
        # The flights that flew to Huston (IAH or HOU)
        flights |>
          filter(dest %in% c('IAH', 'HOU')) 
        ```

    -   Were operated by United, American, or Delta.

        ```{r}
        # The flights that were operated by United (UA), American (AA) or Delta (DL)
        flights |>
          filter(carrier %in% c('UA', 'AA', 'DL')) 
        ```

    -   Departed in summer (July, August, and September).

        ```{r}
        # The flights that departed in summer (July, August, and September)
        flights |>
          filter(month %in% c(7, 8, 9)) 
        ```

    -   Arrived more than two hours late but didn't leave late.

        ```{r}
        # The flights that arrived more than two hours late but didn't leave late
        flights |>
          filter(arr_delay > 120, dep_delay <= 0) 
        ```

    -   Were delayed by at least an hour but made up over 30 minutes in flight.

        ```{r}
        # The flights that were delayed by at least an hour but made up over 30 minutes in flight
        flights |>
          filter(arr_delay > 60, dep_delay - arr_delay > 30) 
        ```

2.  Sort `flights` to find all flights with the longest departure delays. Find the flights that left earliest in the morning.

    ```{r}
    # Find all flights with the longest departure delays
    flights |>
      arrange(desc(dep_delay)) |>
      arrange(sched_dep_time)
    ```

3.  Sort `flights` to find the fastest flights.

    ```{r}
    flights |>
      arrange(desc(distance/air_time))
    ```

4.  Where there a flight on every day of 2013?

    ```{r}
    flights |>
      distinct(month, day) |>
      nrow() == 365
    ```

5.  Which flights traveled the farthest distance? Which traveled the least distance?

    ```{r}
    # Flights that traveled the farthest distance
    flights |> 
      arrange(desc(distance))
      
    # Flights that traveled the least distance
    flights |> 
      arrange(distance)
    ```

6.  Does it matter what order you used `filter()` and `arrange()` if you're using both? Why/Why not?

    The order matters in terms of efficiency. If `filter()` is applied first, then the sorting induced by `arrange()` will apply only on the filtered data frame (generally smaller) hence faster. Other way around, if `arrange()` is applied first, the sorting is applied on the complete data frame, before the filtering takes place.

## Columns {#sec-columns}

There are four important verbs that affect the columns without changing the rows: `mutate()` creates new columns that are derived from the existing columns, `select()` changes which columns are present, `rename()` changes the names of the columns and `relocate()` changes the positions of the columns.

### `mutate()`

The job of `mutate()` is to add new columns that are calculated from the existing columns. In the transform chapters you'll learn a large set of functions that you can use to manipulate different type of variables. For now, we'll stick with basic algebra, which allows us to compute the `gain`, how much time a delayed flight made up in the air and the `speed` in miles per hour:

```{r}
flights |>
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60
  )
```

By default, `mutate()` adds new columns on the right-hand side of your dataset, which makes it difficult to see what's happening here. We can use `.before` argument to instead add the variables to the left-hand side:

```{r}
flights |>
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time *60,
    .before = 1
  )
```

The `.` indicates that `.before` is an argument to the function, not the name of a third new variable we are creating. You can also use `.after` to add after a variable, and in both `.before` and `.after` you can use the variable name instead of position. For example we could add the new variables after `day`:

```{r}
#| results: false

flights |>
  mutate(
    gain = dep_delay - arr_delay,
    speed = distance / air_time * 60,
    .after = day
  )
```

Alternatively, you can control which variables are kept with the `.keep` argument. A particularly useful argument is "used", which specifies that we only keep the columns that were involved or created in `mutate()` step. For example, the following output will contain only the variables `dep_delay`, `arr_delay`, `air_time`, `hours`, `gain`, `gain_per_hour`.

```{r}
#| results: false

flights |>
  mutate(
    gain = dep_delay - arr_delay,
    hours = air_time / 60, 
    gain_per_hour = gain / hours,
    .keep = 'used'
  )
```

Note that since we haven't assigned the result of the about computation back to `flights`, the new variables `gain`, `hours`, and `gain_per_hour` will only be printed but will not be stored in a data frame. And if we want them to be variable in a data frame for future use, we should think carefully about whether we want the result to be assigned back to flights, overwriting the original data frame with many more variable or to a new object. Often, the right answer is a new object that is named informatively to indicate its contents, e.g. `delay_gain`, but you might also have good reasons for overwriting `flights`.

### `select()`

It's not uncommon to get datasets with hundreds or even thousands of variables. In this situation, the first challenge is often just focusing on the variables you're interested in. `select()` allows you to rapidly zoom in on a useful subset using operations based on the names of the variables:

-   Select columns by name:

    ```{r}
    #| results: false

    flights |>
      select(year, month, day)
    ```

-   Select all columns between year and day (inclusive):

    ```{r}
    #| results: false

    flights |>
    select(year:day)
    ```

-   Select all columns except those from year to day (inclusive):

    ```{r}
    #| results: false

    flights |>
      select(!year:day)
    ```

    Historically this operator was done with `-` instead of `!`, so you're likely to see that in the wild. These two operators serve the same purpose but with subtle differences in behavior. We recommend using `!` because it reads as "not" and combines well with `&` and `|`.

-   Select all columns that are characters:

    ```{r}
    #| results: false

    flights |>
      select(where(is.character))
    ```

There are a number of helper functions you can use within `select()`

-   `starts_with('abc')`: matches names that begin with 'abc'.
-   `ends_with('xyz')`: matches names that end with 'xyz'.
-   `contains('ijk')`: matches names that contain 'ijk'.
-   `num_range('x', 1:3)`, matches `x1`, `x2` and `x3`.

See `?select` for more details. Once you know regular expressions, you'll also be able to use `matches()` to select variables that match a pattern.

You can rename variables as you `select()` them by using `=`. The new name appears on the left-hand side of the `=`, and the old variable appears on the right-hand side:

```{r}
flights |>
  select(tail_num = tailnum)
```

### `rename()`

If you to keep all the existing variables and just want to rename a few, you can use `rename()` instead of `select()`:

```{r}
flights |>
  rename(tail_num = tailnum)
```

If you have a bunch of inconsistently named columns and it would be painful to fix them all by hand, check out `janitor::clean_names()` which provides some useful automated cleaning.

### `relocate()`

Use `relocate()` to move variables around. You might want to collect related variables together or move important variables to the front. By default, `relocate()` moves variables to the front:

```{r}
flights |>
  relocate(time_hour, air_time)
```

You can also specify where to put them using `.before` and `.after` arguments, just like in `mutate()`:

```{r}
#| results: false

flights |>
  relocate(year:dep_time, .after = time_hour)
```

```{r}
#| results: false

flights |>
  relocate(starts_with("arr"), .before = dep_time)
```

### Exercises

1.  Compare `dep_time`, `sched_dep_time` and `dep_delay`. How would you expect those three numbers to be related?

    We expect, `dep_time` = `sched_dep_time` + `dep_delay`.

    ```{r}
    flights |>
      select(dep_time, sched_dep_time, dep_delay)
    ```

    To check if the expected relationship holds, `mutate()` can be used in order to create a column that checks the equality between `dep_time` and `sched_dep_time` + `dep_delay`. Since both `dep_time` and `sched_dep_time` are coding the (departure and scheduled departure) time using `xyz` where `x` represents the hour and `yz` the minutes, in `mutate()` corresponding columns are created as well, representing the number of minutes. The dataframe is then filtered for the values where the equality does not hold:

    ```{r}
    flights |>
      mutate(
        dep_time_min = dep_time %/% 1e2 * 60 + dep_time %% 1e2,
        sched_dep_time_min = sched_dep_time %/% 1e2 * 60 + sched_dep_time %% 1e2,
        equality = dep_time_min == (sched_dep_time_min + dep_delay)
      ) |>
      select(dep_time, sched_dep_time, dep_delay, equality) |>
      filter(!equality)
    ```

    There are 1207 flights for which the expected relationship does not hold. This is because there are flights that have the departure the next day, with respect to the scheduled departure. Hence, the expected relationship is `dep_time` = (`sched_dep_time` + `dep_delay`) modulo 1440. We check for this realtionship using the same approach as before:

    ```{r}
    flights |>
      mutate(
        dep_time_min = dep_time %/% 1e2 * 60 + dep_time %% 1e2,
        sched_dep_time_min = sched_dep_time %/% 1e2 * 60 + sched_dep_time %% 1e2,
        equality = dep_time_min == ((sched_dep_time_min + dep_delay) %% 1440),
      ) |>
      select(dep_time, sched_dep_time, dep_delay, equality) |>
      filter(!equality)
    ```

    There are still 29 flights for which the expected relationshop does not hold. All flights for which the relationship does not hold are flights with the departure time codded as `2400`:

    ```{r}
    (flights |>
      mutate(
        dep_time_min = dep_time %/% 1e2 * 60 + dep_time %% 1e2,
        sched_dep_time_min = sched_dep_time %/% 1e2 * 60 + sched_dep_time %% 1e2,
        equality = dep_time_min == ((sched_dep_time_min + dep_delay) %% 1440),
      ) |>
      select(dep_time, sched_dep_time, dep_delay, equality) |>
      filter(!equality) |>
      pull(dep_time) == 2400) |>
    all()
    ```

    Hence the relation between `dep_time`, `sched_dep_time` and `dep_delay` is `dep_time` modulo 1440 = (`sched_dep_time` + `dep_delay`) modulo 1440, provided that `dep_time` and `sched_dep_time` are transformed in minutes.

2.  Brainstorm as many ways as possible to select `dep_time`, `dep_delay`, `arr_time` and `arr_delay` from `flights`.

    ```{r}
    # Using the column names
    s1 <- flights |>
        select(dep_time, dep_delay, arr_time, arr_delay)

    # Using the column positions
    s2 <- flights |>
        select(c(4, 6, 7, 9))

    # Using column names and `contains()`
    s3 <- flights |>
      select(dep_time:arr_delay, -contains("sched"))

    # Using `contains()`
    s4 <- flights |>
        select(contains(c('dep_', 'arr_')), -contains("sched"))

    # Using `starts_with()`
    s5 <- flights |>
      select(starts_with(c('dep', 'arr')))

    # Checking if the (selected) data frames are identical
    c(all.equal(s1, s2), all.equal(s1, s3), all.equal(s1, s4),
      all.equal(s1, s5))
    ```

3.  What happens if you specify the name of the same variable multiple times in a `select()` call?

    It will only select the specified column only once.

    ```{r}
    flights |>
      select(year, year)
    ```

4.  What does the `any_of()` function do? Why might it be helpful in conjunction with this vector?

    ```{r}
    variables <- c('year', 'month', 'day', 'dep_delay', 'arr_delay')
    ```

    From the help page of `any_of`:

    > These selection helpers select variables contained in a character vector. They are especially useful for programming with selecting functions.
    >
    > `all_of()` is for strict selection. If any of the variables in the character vector is missing, an error is thrown.
    >
    > `any_of()` doesn't check for missing variables. It is especially useful with negative selections, when you would like to make sure a variable is removed.

    ```{r}
    flights |>
      select(any_of(variables))
    ```

5.  Does the result of running the following code surprise you? How do the select helpers deal with upper and lower case by default? How can you change that default?

    ```{r}
    flights |>
      select(contains("TIME"))
    ```

    The result is not surprising because, by default, the select helpers ignore cases. In order to make it case sensitive, `ignore.case` has to be set to `FALSE`, i.e. `ignore.case = FALSE`:

    ```{r}
    flights |>
      select(contains("TIME", ignore.case = FALSE))
    ```

    In this case, no column is selected, resulting in a tibble with zero columns.

6.  Rename `air_time` to `air_time_min` to indicate units of measurement and move it to the beginning of the data frame.

    ```{r}
    flights |>
      # Renaming
      rename(air_time_min = air_time) |>
      # Relocating 
      relocate(air_time_min, .before = 1)
    ```

7.  Why doesn’t the following work, and what does the error mean?

    ```{r}
    #| error: true

    flights |>
      select(tailnum) |>
      arrange(arr_delay)
    ```

    `select(tailnum)` selects (only) the `tailnum` variable, so effectively the data frame is a one-column data frame. Any dplyr verb (and any function in general) that takes as paramter any other variable except `tailnum` would throw an error since the variable can't be found.

## The pipe {#sec-the-pipe}

We've shown you simple examples of the pipe above, but its real power arises when you start to combine multiple verbs. For example, imagine that you want to find the fastest flight to Houston's IAH airport: you need to combine `filter()`, `mutate()`, `select()`, and `arrange()`:

```{r}
flights |>
  filter(dest == "IAH") |>
  mutate(speed = distance / air_time * 60) |>
  select(year:day, dep_time, carrier, flight, speed) |>
  arrange(desc(speed))
```

Even though this pipeline has four steps, it's easy to skim because the verbs come at the start of each line: start with `flights` data, then filter, then mutate, then select, then arrange.

What would happen if we didn't have the pipe? We could nest each function call inside the previous call:

```{r}
arrange(
  select(
    mutate(
      filter(
        flights, 
        dest == "IAH"
      ),
      speed = distance / air_time * 60
    ),
    year:day, dep_time, carrier, flight, speed
  ),
  desc(speed)
)
```

Or we could use a bunch of intermediate objects:

```{r}
flights1 <- filter(flights, dest == "IAH")
flights2 <- mutate(flights1, speed = distance / air_time * 60)
flights3 <- select(flights2, year:day, dep_time, carrier, flight, speed)
arrange(flights3, desc(speed))
```

While both forms have their time and place, the pipe generally produces data analysis code that is easier to write and read.

To add the pipe to your code, we recommend using the built-in keyboard shortcut <kbd>⌘</kbd> + <kbd>⇧</kbd> + <kbd>M</kbd>. You'll need to make one change to your RStudio options to use `|>` instead of `%>%`, as shown in @fig-pipe-native.

```{r}
#| label: fig-pipe-native
#| echo: false
#| fig-cap: To insert `|>` make sure the "Use native pipe operator" option is checked.

knitr::include_graphics("book-figs/pipe-native.png")
```

::: callout-note
## **magrittr**

If you've been using tidyverse for a while you might be familiar with the `%\>%` pipe provided by the **magrittr** package. The magrittr package is included in the core tidyverse, so you can use `%\>%` whenever you load the tidyverse:

```{r}
#| eval: false
library(tidyverse)

mtcars %>%
  group_by(cyl) %>%
  summarize(n = n())
```

For simple cases, `|>` and `%>%` behave identically. So why do we recommend the base pipe? Firstly, because it's part of base R, it's always available for you to use, even when you're not using the tidyverse. Secondly, `|>` is quite a bit simpler than `%>%`: in the time between the invention of `%>%` in 2014 and the inclusion of `|>` in R 4.1.0 in 2021, we gained a better understand of the pipe. This allowed the base implementation to jettison infrequently used and less important features.
:::

## Groups {#sec-groups}

So far you've learned about functions that work with rows and columns. dplyr gets even more powerful when you add the ability to work with groups. In this section, we'll focus on the most important functions: `group_by()`, `summarize()`, and the slice family of functions.

### `group_by()`

Use `group_by()` to divide your dataset into groups meaningful for your analysis:

```{r}
flights |>
  group_by(month)
```

`group_by()` doesn't change the data but, if you look closely at the output, you'll notice that the output indicates that it "grouped by" month (`Groups:   month [12]`). This means subsequent operations will now work "by month". `group_by()` adds this grouped feature (referred to as class) to the data frame, which changes the behavior of the subsequent verbs applied to the data.

### `sumarize()` {#sec-sumarize}

The most important grouped operation in a summary, which, if being used to calculate a single summary statistic, reduces the data frame to have a single row for each group. In dplyr, this operation is performed by `summarize()`, as shown by the following example, which computes the average departure delay by month:

```{r}
flights |>
  group_by(month) |>
  summarize(avg_delay = mean(dep_delay))
```

All of our results are `NA`s, R's symbol for missing value. This happened because some of the observed flights had missing data in the delay column, and so when we calculated the mean including those values we got an `NA` result. Missing values are discussed in detail in @sec-missing-values. For now, we'll tell the `mean()` function to ignore all missing values by setting the argument `na.rm` to `TRUE`:

```{r}
flights |>
  group_by(month) |>
  summarize(avg_delay = mean(dep_delay, na.rm = TRUE))
```

You can create any number of summaries in a single call to `summarize()`. You'll learn various useful summaries in the upcoming chapters, but one very useful summary is `n()`, which returns the number of rows in each group:

```{r}
flights |>
  group_by(month) |>
  summarise(
    avg_delay = mean(dep_delay, na.rm = TRUE),
    n = n()
  )
```

Means and counts can get you a surprisingly long way in data science.

### The `slice_` functions

There are five handy functions that allow you to extract specific rows within each group:

-   `df |> slice_head(n = 1)` takes the first row from each group.
-   `df |> slice_tail(n = 1)` takes the last row in each group.
-   `df |> slice_min(x, n = 1)` takes the row with the smallest value of column `x`.
-   `df |> slice_max(x, n = 1)` takes the row with the largest value of column `x`.
-   `df |> slice_sample(n = 1)` takes one random sample.

You can vary `n` to select more than one row, or instead of `n =` you can use `prop = 0.1` to select (e.g.) 10% of the rows in each group. For example, the following code finds the flights that are most delayed upon arrival at each destination

```{r}
flights |>
  group_by(dest) |>
  slice_max(arr_delay, n = 1) |>
  relocate(dest)
```

Not that there are 105 destinations but we get 108 rows here. What's up? `slice_min()` and `slice_max()` keep tied valued so `n = 1` means give us all rows with the highest value. If you want exactly one row per group you can set `with_ties = FALSE`.

This is similar to computing the max delay with `summarize()`, but you get the whole corresponding row (or rows if there's a tie) instead of single summary statistic.

### Grouping by multiple variables

You can create groups using more than one variable. For example, we could make a group for each date.

```{r}
daily <- flights |>
  group_by(year, month, day)
daily
```

When you summarize a tibble grouped by more than one variable, each summary peels of the last group. In hindsight, this wasn't a great to make this function work, but it's difficult to change without breaking existing code. To make it obvious what's happening, dplyr displays a message that tells you how you can change this behavior:

```{r}
daily_flights <- daily |>
  summarise(n = n())
```

If you are happy with this behavior, you can explicitly request it in order to suppress the message:

```{r}
daily_flights <- daily |>
  summarise(n = n(), .groups = "drop_last")
```

Alternatively, change the default behavior by setting a different value e.g. `"drop"` to drop all grouping or `"keep"` to preserve the same groups.

### Ungrouping

You might also want to remove grouping from a data frame without using `summarise()`. You can do this with `ungroup()`.

```{r}
daily |>
  ungroup()
```

Now let's see what happens when you summarize an ungrouped data frame.

```{r}
daily |>
  ungroup() |>
  summarise(avg_delay = mean(dep_delay, na.rm = TRUE),
            flights = n())
```

You get a single row back because dplyr treats all the rows in an ungrouped data frame as belonging to one group.

### `.by`

dplyr 1.1.0 includes a new, experimental, syntax for per-operation grouping, the `.by` argument. `group_by()` and `ungroup()` aren't going away but you can now also use the `.by` argument to group within a single operation:

```{r}
flights |>
  summarise(delay = mean(dep_delay, na.rm = TRUE),
            n = n(),
            .by = month)
```

Or if you want to group by multiple variables:

```{r}
flights |>
  summarise(delay = mean(dep_delay, na.rm = TRUE),
            n = n(),
            .by = c(origin, dest))
```

`.by` works with all verbs and has the advantage that you don't need to use the `.groups` argument to suppress the grouping message or `ungroup()` when you're done.

### Exercises

1.  Which carrier has the worst average delays? Challenge: can you disentangle the effects of bad airports vs bad carriers? Why/why not? (Hint: think about `flights |> group_by(carrier, dest) |> summarize(n())`)

    For determining the carrier that has the worst average delays, the carrier variable has to be grouped (`group_by(carrier)`), the mean of the delays computed (`mean(arr_delay, na.rm = TRUE)`) and the dataframe arranged in descending order (highest average arrival delays on top):

    ```{r}
    overall_mean_delay <- flights |>
      group_by(carrier) |>
      summarise(avg_arr_delay = mean(arr_delay, na.rm = TRUE))
      

    overall_mean_delay |>
      arrange(desc(avg_arr_delay))
    ```

    The visualization can be done using a bar plot.

    ```{r}
    overall_mean_delay |>
      filter(!is.na(avg_arr_delay)) |> 
      ggplot(
        aes(
          x = avg_arr_delay, 
          y = fct_reorder(fct(carrier), avg_arr_delay)
        )
      ) +
      geom_bar(fill = "tomato", stat = "identity") +
      labs(
        x = "Avgerage arrival delay (minutes)",
        y = "Carrier"
      )
    ```

    The same computation can be done without using `group_by()` using just `summarise()` and the parameter `.by`:

    ```{r}
    #| results: false

    flights |>
      summarise(avg_arr_delay = mean(arr_delay, na.rm = TRUE),
                .by = carrier)
    ```

    The computation above simply consideres the average arrival delay. A more granular image can be given by computing the average arrival delay for each airport and comparing every carrier's average arrival delay for that airport with the airport's average arrival delay. We can then count, for each carrier, the number of airports where the carrier's average arrival delay is higher than the airport's average arrival delay. The following chunks contain the code corresponding to these calculation.

    The next chunk is computing carrier's average arrival delay for each of the destination airports. This is done by grouping the data frame by `carrier, dest` and computing the mean for each group, using `summarise()`:

    ```{r}
    dest_carrier_mean_arr_delay <- flights |>
      group_by(carrier, dest) |>
      summarise(
        mean_dest_carrier = mean(arr_delay, na.rm = TRUE), 
        .groups = "drop_last"
      ) |>
      ungroup()

    dest_carrier_mean_arr_delay
    ```

    The next chunk is computing the average arrival delay for each of the destination airports. This is done by grouping the data frame by `dest` and computing the mean for each group, using `summarise()`:

    ```{r}
    dest_mean_arr_delay <- flights |>
      group_by(dest) |>
      summarise(
        mean_dest = mean(arr_delay, na.rm = TRUE), 
      )

    dest_mean_arr_delay |>
      arrange(desc(mean_dest))
    ```

    The two data frames are joined (by the common column `dest`), with the resulting data frame containing `dest_carrier_mean_arr_delay` and an additional column, representing the airports average arrival delays. The data frame is then mutated by adding a boolean variable, `TRUE` for the observations where carrier's average arrival delay is higher than the airport's average arrival delay.

    ```{r}
    larger <- dest_carrier_mean_arr_delay |>
      
      left_join(
        dest_mean_arr_delay,
        by = join_by(dest)
        ) |>
      mutate(
        larger = mean_dest_carrier > mean_dest
      ) |>
      select(carrier, larger)

    larger
    ```

    Counting the number of `TRUE` values in `larger_than_mean_dest` for each carrier, via `summarise()` gives the number of airports for which a carrier's mean arrival dealy is higher than the airport's mean arrival delay:

    ```{r}
    delayed_airports <- larger |>
      summarise(
        n_delayed = sum(larger),
        .by = carrier
      ) |> 
      filter(!is.na(n_delayed))
      
    delayed_airports |>
      arrange(desc(n_delayed))
    ```

    The visualization can be done using a bar plot.

    ```{r}
    delayed_airports |>
      ggplot(
        aes(
          x = n_delayed, 
          y = fct_reorder(fct(carrier), n_delayed)
        )
      ) +
      geom_bar(fill = "tomato", stat = "identity")  +
      labs(
        x = "Number of airports with higher than average delay",
        y = "Carrier"
      )
    ```

    The carriers with the worst (overall) average dealys, `F9` and `FL` are actually bettwen the carriers with the smallest number of airports with higher than average delays. That is because both carriers are operating 1 and 3 airports respectively. This can be computed using the same approach as before, using `distinct()` and `sumarise()`:

    ```{r}
    operated_airports <- flights |>
      distinct(carrier, dest) |>
      summarise(
        n_operated = n(),
        .by = carrier
      ) 

    operated_airports |>
      arrange(desc(n_operated))
    ```

    As before, the visualization can be done using a bar plot.

    ```{r}
    operated_airports |>
      ggplot(
        aes(
          x = n_operated, 
          y = fct_reorder(fct(carrier), n_operated)
        )
      ) +
      geom_bar(fill = "tomato", stat = "identity")  +
      labs(
        x = "Number of operated airports",
        y = "Carrier"
      )
    ```

    A more legitimate criterion to rank the carriers is the proportion between the the carrier's number of airports with higher than airport's mean arrival delay and carrier's total number of operated airports. This can be done by joining `delayed_airports` and `operated_airports` adn computing the proportion:

    ```{r}
    proportion_delayed_airports <- delayed_airports |>
      left_join(
        operated_airports, 
        by = join_by(carrier)
      ) |>
      mutate(
        prop = n_delayed / n_operated
      ) |>
      select(carrier, prop)
      
    proportion_delayed_airports |>
      arrange(desc(prop))
    ```

    As before, the visualization can be done using a bar plot.

    ```{r}
    proportion_delayed_airports |>
      ggplot(
        aes(
          x = prop, 
          y = fct_reorder(fct(carrier), prop)
        )
      ) +
      geom_bar(fill = "tomato", stat = "identity")  +
      labs(
        x = "Proportion of airports with higher than mean delay",
        y = "Carrier"
      )
    ```

2.  Find the flights that are most delayed upon departure from each destination.

    This can be done by grouping the data frame by destination `group_by(dest)` and selecting (in each group) the flights with highest departure delay, `slice_max(dep_delay, n = 1)`:

    ```{r}
    flights |>
      group_by(dest) |>
      slice_max(dep_delay, n = 1) |>
      select(origin, dest, dep_delay)
    ```

3.  How do delays vary over the course of the day?

    The dataset contains the the columns `hour`, corresponding to the schedule departing hour. We can group by this column and then compute the average departure delay, using `sumarise()` and the plot the schedule departure hour versus the average delay (in minutes).

    ```{r}
    flights |>
      group_by(hour) |>
      summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE)) |>
      ggplot(aes(x = hour, y = avg_dep_delay)) +
      geom_point(color = "tomato",
                 size = 3, 
                 na.rm = TRUE) + 
      labs(
        x = "Scheduled departure (hour)",
        y = "Average delay (minutes)",
        title = "Average delay vs. departure hour"
      )
    ```

    The same computations can be done without using `group_by()`, by using `summarise()` using the function parameter `.by`:

    ```{r}
    #| fig.show: hide

    flights |>
      summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE),
                .by = hour) |>
      ggplot(aes(x = hour, y = avg_dep_delay)) +
      geom_point(color = "tomato",
                 size = 3, 
                 na.rm = TRUE) + 
      labs(
        x = "Scheduled departure (hour)",
        y = "Average delay (minutes)",
        title = "Average delay vs. departure hour"
      )
    ```

    There is only one flight with a scheduled departure time between 0 and 4:

    ```{r}
    flights |>
      filter(hour %in% c(0,1,2,3,4))
    ```

    Since there is only one flight and no `dep_delay` data corresponding to this flight, i.e. there is a `NA` value in the `dep_delay` column the data set that is plotted has in the `hour` column values from 5 to 23 and also 1. The corresponding average departure delay for hour 1 is `NA`. We can drop that recording for a more informative plot (starting from 5 to 23 on the x-axis):

    ```{r}
    flights |>
      summarise(avg_dep_delay = mean(dep_delay, na.rm = TRUE),
                .by = hour) |>
      drop_na() |>
      ggplot(aes(x = hour, y = avg_dep_delay)) +
      geom_point(color = "tomato",
                 size = 3, 
                 na.rm = TRUE) + 
      labs(
        x = "Scheduled departure (hour)",
        y = "Average delay (minutes)",
        title = "Average delay vs. departure hour"
      )
    ```

    Another way to visualize the variation of delays over the day is using boxplots. The following chink is plots the departure delay boxplots corresponding to departure hours. (Outliers would make the figure difficult to interpret so they are removed. As before, sincethe corresponding average departure delay for hour 1 is `NA` it will be removed from the plot for a better visualization)

    ```{r}
    flights |>
      filter(hour != 1) |>
      group_by(hour) |>
      ggplot(aes(x = as_factor(hour), y = dep_delay)) +
      geom_boxplot(outliers = FALSE, fill = "tomato") +
      labs(
        x = "Scheduled departure (hour)",
        y = "Departure delay (minutes)",
        title = "Departure delay vs. departure hour"
      )
    ```

4.  What happens if you supply a negative `n` to `slice_min()` and friends?

    From `?slice_min` (or the help webpage from [slice](https://dplyr.tidyverse.org/reference/slice.html)):

    > A negative value of n or prop will be subtracted from the group size. For example, n = -2 with a group of 5 rows will select 5 - 2 = 3 rows; prop = -0.25 with 8 rows will select 8 \* (1 - 0.25) = 6 rows.

5.  Explain what `count()` does in terms of the dplyr verbs you just learned. What does the `sort` argument to `count()` do.

    `count()` is a verb used when the goal is counting the number of occurrences. In terms of dplyr verbs it is equivalent to using `summarise(n = n())` over a grouped data frame (group_by(x)) or with `.by = x`. More rigurously:

    > `df |> summarise(n = n(), .by = x) |> arrange(x)`\
    > is equivalent to\
    > `df |> count(x)`

    E.g., if the goal is to compute the number of flights coming from New York to each airport, `summarise(n = n(), .by = dest)` or `count(dest)` can be used:

    ```{r}
    dest1 <- flights |>
      summarise(
        n = n(), 
        .by = dest
      ) |>
      arrange(dest)

    dest2 <- flights |>
      count(dest)
    ```

    The resulting data frames are identical:

    ```{r}
    all.equal(dest1, dest2)
    ```

    The additional step where `arrange()` verb is used is to obtain an identical data frame, i.e. arranged like the one corresponding to using `count()`. Using just `df |> summarise(n = n(), .by = x)` returns a data frame that contains the same observations as the one corresponding to`count()`, but ordered differently.

    The equivalence stands when more than one variable (column) is used as a parameter, i.e.:

    > `df |> summarise(n = n(), .by = c(x, y)) |> arrange(x, y)`\
    > is equivalent to\
    > `df |> count(x, y)`

    E.g., when the goal is to count the number of flights between each origin and destination airport, `summarise(n = n(), .by = c(origin, dest)) |> arrange(origin, dest)` or `count(origin, dest)` can be used:

    ```{r}
    origin_dest1 <- flights |>
      summarise(
        n = n(), 
        .by = c(origin,dest)
      ) |> 
      arrange(origin, dest)

    origin_dest2 <- flights |>
      count(origin, dest)
    ```

    As expected, the resulting data frames are identical:

    ```{r}
    all.equal(origin_dest1, origin_dest2)
    ```

    The default value if `sort` parameter in `count()` verb is `sort = FALSE`. Setting it to `TRUE` will sort the counts (i.e. the `n` variable) from the highest value to the smallest value. In this case, the equivalence is

    > `df |> summarise(n = n(), .by = c(x, y)) |> arrange(desc(n), x, y)`\
    > is equivalent to\
    > `df |> count(x, y, sort = TRUE)`

    ```{r}
    origin_dest_s1 <- flights |>
      summarise(
        n = n(), 
        .by = c(origin, dest)
      ) |> 
      arrange(desc(n), origin, dest)


    origin_dest_s2 <- flights |>
      count(origin, dest, sort = TRUE)
    ```

    As expected, the resulting data frames are identical:

    ```{r}
    all.equal(origin_dest_s1, origin_dest_s2)
    ```

6.  Suppose we have the following tiny data frame:

    ```{r}
    df <- tibble(x = 1:5,
                 y = c("a", "b", "a", "a", "b"),
                 z = c("K", "K", "L", "L", "K"))
    ```

    a.  Write downs what you think the output will like like, then check if you were correct, and describe what `group_by()` does:

        The tibble is grouped by the values in `y` and since there are two values in `y` there will be two groups (one corresponding to `y = a` and one corresponding to `y = b`). `group_by` will divide the dataset into groups corresponding to values in `y`. All the subsequent operation applied on the diveded dataframe will apply to each group.

        ```{r}
        df |>
          group_by(y)
        ```

    b.  Write down what you think the output will look like, then check if you were correct, and describe what `arrange()` does. Also, comment on how it's diffrent from the `group_by()` in part (a).

        `arrange()` rearanges the tibble in asceding order of the values specified inside `arrange()`, in this case in ascending order for the values corresponding to the `y` column. As opposed to `group_by()`, `arrange()` will not divide (group) the data frame. It will simply re-arange the order of the rows.

        ```{r}
        df |>
          arrange(y)
        ```

        For the desceding order, we can apply `desc()`, in this case `arrange(desc(y))`.

        ```{r}
        df |>
          arrange(desc(y))
        ```

    c.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does.

        -   First the data set is grouped by the values of `y`, hence there will be two groups, one corresponding to `y = a` and one corresponding to `y = b`.
        -   Secondly, each group is summarized in terms of the mean of the `x` variable It will return a two columns data frame (`y`, the column we grouped by and `mean_x`, the summary statistic we compute), with two rows (two values in the `y` column).

        ```{r}
        df |>
          group_by(y) |>
          summarize(mean_x = mean(x))
        ```

    d.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does. Then, comment on what the message says.

        -   Firstly, the data frame is grouped by the combination of values of `y` and `z`, hence there will three groups, the first one corresponding to `y = a` and `z = K`, the second one corresponding to `y = a` and `z = L` and finally the third one corresponding to `y = b` and `z = K` (there won't be a fourth one corresponding to `y = b` and `z = L` since there is no row in the data frame with those values).
        -   Secondly, each group is summarized in terms of the mean of the `x` variable. It returns a three columns data frame (`y` and `z`, the two columns we grouped by and `mean_x`, the summary statistic that is computed) with three rows.

        The final data frame will be grouped by `y`.

        ```{r}
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x))
        ```

    e.  Write down what you think the output will look like, then check if you were correct, and describe what the pipeline does. How is the output different from the one in part (d)?

        The resulting tibble *looks* like the one from (d), except the final data frame won't be grouped, i.e. there won't be any groups.

        ```{r}
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x), .groups = "drop")
        ```

    f.  Write down what you think the outputs will look like, then check if you were correct, and describe what each pipeline does. How are the outputs of the two pipelines different?

        The output corresponding to the first code is covered in (d). The result is a grouped 3 $\times$ 3 tibble grouped by `y` (two groups)

        The second code, firstly groups the data frame and secondly adds a new column `mean_x`, with the corresponding values the means of the three groups. The output is a grouped 5 $\times$ 4 tibble, grouped by `y, z` (three groups).

        ```{r}
        df |>
          group_by(y, z) |>
          summarize(mean_x = mean(x))

        df |>
          group_by(y, z) |>
          mutate(mean_x = mean(x))
        ```

## Case study: aggregates and sample size {#sec-case-study-aggregates}

Whenever you do any aggregation, it's always a good idea to include a count (`n()`). That way, you can ensure that you're not drawing conclusions based on very small amounts of data. We'll demonstrate this with some baseball data from the **Lahman** package. Specifically, we will compare what proportion of times a player gets a hit (`H`) vs. the number of times they try to put the ball in play (`AB`):

```{r}
batters <- Lahman::Batting |>
  group_by(playerID) |>
  summarise(performance = sum(H, na.rm = TRUE) / sum(AB, na.rm = TRUE),
            n = sum(AB, na.rm = TRUE))

batters
```

When we plot the skill of the batter (measured by the batting average, `performance`) against the number of opportunities to hit the ball (measured by times at bat, `n`), you see two patterns:

1.  The variation in `performance` is larger with fewer at-bats. The shape of this plot is very characteristic: whenever you plot a mean (or other summary statistics) vs. group size, you'll see that the variation decreases as the sample size increases.
2.  There's a positive correlation between skill (`performance`) and opportunities to hit the ball (`n`) because teams want to give their best batters the most opportunities to hit the ball.

```{r}
#| message: false
batters |>
  filter(n > 100) |>
  ggplot(aes(x = n, y = performance)) +
  geom_point(alpha = 1 / 10) +
  geom_smooth(se = FALSE)
```

Note the hand pattern for combining ggplot2 and dplyr. You just have to remember to switch from `|>`, for dataset processing, to `+` for adding layers to your plot.

This also has important implications for rankings. If you naively sort on `desc(performance)`, the people with the best batting averages are clearly the ones who tried to put the ball in play very few times and happened to get a hit, they're not necessarily the most skilled players:

```{r}
batters |>
  arrange(desc(performance))
```

You can find a good explanation of this problem and how to overcome it at <http://varianceexplained.org/r/empirical_bayes_baseball/> and <https://www.evanmiller.org/how-not-to-sort-by-average-rating.html>.

## Summary

In this chapter, you’ve learned the tools that dplyr provides for working with data frames. The tools are roughly grouped into three categories:

1.  those that manipulate the rows (like `filter()` and `arrange()`),

2.  those that manipulate the columns (like `select()` and `mutate()`),

3.  those that manipulate groups (like `group_by()` and `summarize()`).
