# Regular expresions {#sec-regular-expressions}

```{r}
#| echo: false

source("_settings.R")
```

## Introduction

In @sec-strings, you learned a whole bunch of useful functions for working with strings. This chapter will focus on functions that use **regular expressions**, a concise and powerful language for describing patterns within strings. The term "regular expression" is a bit of a mouthful so most people abbreviate it to "regex" or "regexp".

The chapter starts with the basis of regular expressions and the most useful stringr functions for data analysis. We'll then expand your knowledge of patterns and cover seven important new topics (escaping, anchoring, character classes, shorthand classes, quantifiers, precedence, and grouping). Next, we'll talk about some of the other types of patterns that stringr functions can work with and the various "flags" that allow you to tweak the operations of regular expressions. We'll finish with a survey of their places in the tidyverse and base R where you might use regexes.

### Prerequisites

In this chapter, we'll use regular expression functions from stringr and tidyr, both core member of the tidyverse, as well as data from the babynames package.

```{r}
#| warning: false
library(tidyverse)
library(babynames)
```

Through this chapter, we'll use a mix of very simple inline examples so you can get the basic idea, the baby names data and three character vector from stringr:

-   `fruit` contains the names of 80 fruits.
-   `words` contains 980 common English words.
-   `sentences` contains 720 short sentences.

## Pattern basics {#sec-pattern-basics}

We'll use `str_view()` to learn how regex patterns work. We used `str_view()` in the last chapter to better understand a string vs. its printed representation, and now we'll use it with its second argument, a regular expression. When this is supplied, `str_view()` will show only the elements of the string vector that match, surrounding each match with `<>`, and where possible, highlighting the match in blue.

The simplest patterns consist of letters and numbers which match those characters exactly:

```{r}
str_view(fruit, "berry")
```

Letters and numbers match exactly and are called **literal characters**. Most punctuation characters, like `.`, `+`, `*`, `[`, `]`, and `?`, have special meanings and are called **metacharacters**. For example, `.` will match any characters (except for `\n`), so `"a."` will match any string that contains an "a" followed by another character:

```{r}
str_view(c("a", "ab", "ac", "bd", "ea", "eab"), "a.")
```

Or we could find all the fruits that contain an "a" followed by three letters, followed by an "e":

```{r}
str_view(fruit, "a...e")
```

**Quantifiers** control how many times a pattern can match:

-   `?` makes a pattern optional (i.e. it matches 0 or 1 times),
-   `+` lets a pattern repeat (i.e. it matches at least once),
-   `*` lets a pattern be optional or repeat (i.e. it matches any number of times, including 0).

```{r}
# ab? matches an "a", optionally followed by a "b".
str_view(c("a", "ab", "abb"), "ab?")

# ab+ matches an "a" followed by an at least one "b".
str_view(c("a", "ab", "abb"), "ab+")

# ab* matches an "a" followed by any number of "b" (including 0)
str_view(c("a", "ab", "abb"), "ab*")
```

**Character classes** are defined by `[]` and let you match a set of characters, e.g., `[abcd]` matches "a", "b", "c" or "d". You can also invert the match by starting with `^`: `[^abcd]` matches anything **except** "a", "b", "c" or "d". We can use this idea to find the words containing an "x" surrounded by vowels, or a "y" surrounded by consonants:

```{r}
str_view(words, "[aeiou]x[aeiou]")
str_view(words, "[^aeiou]y[^aeiou]")
```

You can use **alternation**, `|`, to pick between one or more alternative patterns. For example, the following patterns look for fruits "apple", "melon" or "nut", or a repeated vowel.

```{r}
str_view(fruit, "apple|melon|nut")
str_view(fruit, "aa|ee|ii|oo|uu")
```

Regular expressions are very compact and use a lot of punctuation characters, so they can seem overwhelming and hard to read at first. Don't worry; you'll get better with practice, and simple patterns will soon become second nature. Let's kick off that process by practicing with some useful stringr functions.

## Key functions {#sec-key-functions}

Now that you've got the basics of regular expressions under your belt, let's use them with some stringr and tidyr functions. In the following section, you'll learn how to detect the presence or absence of a match, how to count the number of matches, how to replace a match with fixed text, and how to extract text using a pattern.

### Detect matches

`str_detect()` returns a logical vector that is `TRUE` if the pattern matches an element of the character vector and `FALSE` otherwise:

```{r}
str_detect(c("a", "b", "c", "d", "e"), "[aeiou]")
```

Since `str_detect()` returns a logical vector of the same length as the initial vector, it pairs will with `filter()`. For example, this code finds all the most popular names containing a lower-case "x":

```{r}
babynames |>
  filter(str_detect(name, "x")) |>
  count(name, wt = n, sort = TRUE)
```

We can also use `str_detect()` with `summarize()` by pairing it with `sum()` or `mean()`: `sum(str_detect(x, pattern))` tells you the number of observations that match and `mean(str_detect(x, pattern))` tells you the proportion of the match. For example, the following snippet computes and visualizes the proportion of baby names that contain `x`, broken down by year. It looks like they've radically increased in popularity lately:

```{r}
babynames |>
  summarise(
    prop_x = mean(str_detect(name, "x")),
    .by = year
  ) |>
  ggplot(aes(x = year, y = prop_x)) +
  geom_line(color = "tomato") +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Proportion of names containg letter x",
    x = "Year",
    y = "Proportion"
  )
```

There are two functions that are closely related to `str_delect()`: `str_subset()` and `str_which()`.

-   `str_subset()` returns a character vector containing only the strings that match.
-   `str_which()` returns an integer vector giving the positions of the strings that match.

### Count matches

The next step up in complexity from `str_detect()` is `str_count()`: rather than a true or false, it tells you how many matches there are in each string.

```{r}
x <- c("apple", "banana", "pear")
str_count(x, "p")
```

Note that each match starts at the end of the previous match, i.e. regex matches never overlap. For example, in "abababa", how many times will the pattern "aba" match? Regular expressions say two, not three:

```{r}
str_count("abababa", "aba")
str_view("abababa", "aba")
```

It is natural to use `str_count()` with `mutate()`. The following example uses `str_count()` with character classes to count the number of vowels and consonants in each name.

```{r}
babynames |>
  count(name) |>
  mutate(
    n_vowels = str_count(name, "[aeiou]"),
    n_consonants = str_count(name, "[^aeiou]"),
    )
```

If you look closely, you'll notice that there's something off with our calculations: "Aaban" contains three "a"s, but our summary reports only two vowels. That's because regular expressions are case sensitive. There three ways we could fix this:

-   Add the upper case vowels to the character class: `str_count(name, "[aeiouAEIOU]")`.
-   Tell the regular expression to ignore case: `str_count(name, regex("[aeiou]", ignore_case = TRUE))`.
-   Use `str_to_lower()` to convert the names to lower case: `str_count(str_to_lower(name), "[aeiou]")`

This variety of approaches is pretty typical when working with strings -- there are often multiple ways to reach your goal, either by making your pattern more complicated or by doing some preprocessing on your string. If you get stuck trying one approach, it can often be useful to switch gears and tackle the problem from a different perspective.

In this case since we're applying two functions to the name, I think it's easier to transform it first:

```{r}
babynames |>
  count(name) |>
  mutate(
    name = str_to_lower(name),
    n_vowels = str_count(name, "[aeiou]"),
    n_consonants = str_count(name, "[^aeiou]")
  )
```

### Replace values

As well as detecting and counting matches, we can also modify them with `str_replace()` and `str_replace_all()`:

-   `str_replace()` replaces the first match,
-   `str_replace_all()` replaces all matches.

```{r}
x <- c("apple", "pear", "banana")
str_replace(x, "[aeiou]", "-")
str_replace_all(x, "[aeiou]", "-")
```

`str_remove(x, pattern)` and is a handy shortcut for `str_replace(x, pattern, "")` and `str_remove_all()` is a hand shortcut for `str_replace_all(x, pattern, "")`:

```{r}
x <- c("apple", "pear", "banana")
str_remove(x, "[aeiou]")
str_remove_all(x, "[aeiou]")
```

These functions are naturally paired with `mutate()` when doing data cleaning, and you'll often apply them repeatedly to peal off layers of inconsistent formatting.

### Extract variables

The last function we'll discuss uses regular expressions to extract data out of one column into one or more new columns: `separate_wider_regex()`. It's a pear of the `separate_wider_position()` and `separate_wider_delim()` functions that you learned about @sec-strings. These functions live in the tidyr because they operate on (columns of) data frames, rather than individual vectors.

Let's create a simple dataset to show how it works. Here we have some data derived from `babynames` where we have the name, gender and age of a bunch of people in a rather weird format:

```{r}
#| results: false
df <- tribble(
  ~str,
  "<Sheryl>-F_34",
  "<Kisha>-F_45",
  "<Brandon>-N_33",
  "<Sharon>-F_38",
  "<Penny>-F_54",
  "<Justin>-M_41",
  "<Patricia>-F_84",
)
df
```

To extract this data using `separate_wider_regex()` we just need to construct a sequence of regular expressions that match each piece. If we want the contents of that piece to appear in the output, we give it a name:

```{r}
df |>
  separate_wider_regex(
    str, 
    patterns = c(
      "<", 
      name = "[A-Za-z]+",
      ">-", 
      gender = ".",
      "_",
      age = "[0-9]+"
      )
    )
```

If the match fails, you can use `too_few = "debug"` to figure out what went wrong, just like `separate_wider_delim()` and `separate_wider_position()`.

### Exercises

1.  What baby name has the most vowels? What names has the highest proportion of vowels? (Hint: what is the denominator?)

    ```{r}
    babynames |>
      mutate(n_vowels = str_count(str_to_lower(name), "[aeiou]")) |>
      slice_max(n_vowels) |>
      distinct(name, .keep_all = TRUE) |>
      select(sex, name, n_vowels)
    ```

    ```{r}
    babynames |>
      mutate(prop_vowels = str_count(str_to_lower(name), "[aeiou]") / str_length(name)) |>
      slice_max(prop_vowels) |>
      distinct(name, .keep_all = TRUE) |>
      select(sex, name, prop_vowels)
    ```

2.  Replace all forward slashes in "a/b/c/d/e" with back slashes. What happens if you attempt to undo the transformation by replacing all backslashes with forward slashes?

    ```{r}
    text <- "a/b/c/d/e"
    str_view(text)
    text_1 <- str_replace_all(text, "/", "\\\\")
    str_view(text_1)
    text_2 <- str_replace_all(text, "\\\\", "/")
    str_view(text_2)
    ```

3.  Implement a simple version of `str_to_lower()` using `str_replace_all()`

    An implementation of `str_to_lower()` based on `str_replace_all()` can be easily done using the fact that in `str_replace_all(string, pattern, replacememnt)`, while the default interpretation for `pattern` is a regular expressions it can also be a named vector with the names of the vector representing the patterns and the values the replacements. Using this, we can define a vector based on `letters` named `LETTERS` (i.e. a vector with values the lowercase letters and the corresponding names the uppercase letters).

    ```{r}
    my_str_to_lower <- function(string) {
      pattern <- letters
      names(pattern) <- LETTERS
      str_replace_all(string, pattern)
    }

    test <- c("Abb", "aBa", "A(BB", "aB-bB")
    my_str_to_lower(test)
    ```

4.  Create a regular expression that will match telephone numbers are commonly written in your country.

    ```{r}
    tel_numbs <- c("234-134-1345", "104-124-2299", "125-131-1999")

    regex_tel <- "[0-9]+-[0-9]+-[0-9]+"

    str_view(tel_numbs, regex_tel)
    ```

## Pattern details {#sec-pattern-details}

Now that you understand the basics of the patterns language and how to use it with some stringr and tidyr functions, it's time to dig into more of the details. First we'll start with **escaping**, which allows you to match metacharacters that would otherwise be treated specially. Next you'll learn about **anchors** which allow you match the start or end of the string. Then you'll learn more about **character classes** and their shortcuts which allow you to match any character from a set. Next you'll learn the final details of **quantifiers** which control how many times a pattern can match. Then, we have to cover the important (but complex) topic of **operator precedence** and parentheses. And we'll finish off with some details of **grouping** components of the pattern.

The terms we use here are the technical names for each component. They're not always the most evocative of their purpose but it's very helpful to know the correct terms if you later want to Google for more details.

### Escaping

In order to match a literal `.` you need an **escape** which tells the regular expression to match metacharacters literally. Like strings, regexp use the backslash for escaping. So, to match a `.`, you need the regexp `\.`. Unfortunately, this creates a problem. We use strings to represent regular expressions, and `\` is also used as an escape symbol in strings. So to create the regular expression `\.` we need the string `"\\."`, as the following example shows:

```{r}
# To create the regular expression \. we need to use \\.
dot <- "\\."

# But the expression itself only contains one \
str_view(dot)

# And this tells R to look for an explicit .
str_view(c("abc", "a.c", "bef"), "a\\.c")
```

In this book we'll usually use regular expression without quotes, like `\.`.If we need to emphasize what you'll actually type, we'll surround it with quotes and add extra escapes, like "\\.".

If `\` is used as an escape character in regular expressions, how do you match a literal `\`? Well you need to escape it, creating the regular expression `\\`. To create that regular expression, you need to use a string, which also needs to escape `\`. That means to match a literally `\` you need to write "`\\\\`" -- you need four backslashes to match one.

```{r}
x <- "a\\b"
str_view(x)
str_view(x, "\\\\")
```

Alternatively, you might find it easier to use the raw strings you learned about in @sec-creating-a-string. That lets you avoid one layer of escaping:

```{r}
str_view(x, r"{\\}")
```

If you're trying to match a literal `.`, `$`, `|`, `*`, `+`, `?`, `{`, `}`, `(`, `)`, there is an alternative to using a backslash escape: you can use a character class: `[.]`, `[$]`, `[|]`, ... all match the literal values.

```{r}
str_view(c("abc", "a.c", "a*c", "a c"), "a[.]c")
str_view(c("abc", "a.c", "a*c", "a c"), ".[*]c")
```

### Anchors

By default, regular expressions will match any part of a string. If you want to match at the start or end you need to **anchor** the regular expression using `^` to match the start or `$` to match the end:

```{r}
str_view(fruit, "^a")
str_view(fruit, "a$")
```

It's tempting to think that `$` should match the start of a string, because that' how we write dollar amounts, but that's not what regular expressions want.

To force a regular expression to match only the full string, anchor it with both `^` and `$`:

```{r}
str_view(fruit, "apple")
str_view(fruit, "^apple$")
```

You can also match the boundary between words (i.e. the start or end of a word) with `\b`. This can be particularly useful when using RStudio's find and replace tool. For example, to find all uses of `sum()`, you can search for `\bsum\b` to avoid `summarize`, `summary`, `rowsum` and so on:

```{r}
x <- c("summary(x)","summarize(df)", "rowsum(x)", "sum(x)")
str_view(x, "sum")
str_view(x, "\\bsum\\b")
```

When used alone, anchors will produce a zero width match:

```{r}
str_view("abc", c("^", "$", "\\b"))
```

This helps you understand what happens when you replace a standalone anchor:

```{r}
str_replace_all("abc", c("$", "^", "\\b"), "--")
```

### Character classes

A **character class**, or character **set**, allows you to match any character in a set. As we discussed above you can construct your own sets with `[]`, where `[abc]` matches "a", "b", or "c" and `[^abc]` matches any character except "a", "b", and "c". Apart from `^` there are two other characters that have special meaning inside of `[]`:

-   `-` defines a range, e.g., `[a-z]` matches any lower case letter and `[0-9]` matches any number.

-   `\` escapes special characters, so `[\^\-\]]` matches `^`, `-`, or `]`.

Here are few examples:

```{r}
x <- "abcd ABCD 12345 -!@#%."

# Will match any pattern containing "a", "b" or "c" at
# least once. 
str_view(x, "[abc]+")

# Will match any pattern containing lowercase letters at
# least once. 
str_view(x, "[a-z]+")

# Will match any pattern except lowercase letters or numbers
# at least once
str_view(x, "[^a-z0-9]+")

# Will match any pattern that starts with lowercase letters 
# or numbers
str_view(x, "^[a-z0-9]+")

# You need an escape to match characters that are otherwise 
# special inside of []
str_view("a-b-c", "[a-c]")
str_view("a-b-c", "[a\\-c]")
```

Some characters classes are used so commonly that they get their own shortcut. You've already seen `.`, which matches any character apart from a newline. There are three other particularly useful pairs (remember, to create a regular expression containing `\d` or `\s`, you'll need to escape the `\` for the string, so you'll type `"\\d"` or `"\\s"`).

-   `\d` matches and digit `\D` matches anything that isn't a digit

-   `\s` matches and whitespace (e.g. space, tab, newline) `\S` matches anything that isn't a whitespace

-   `\w` matches any "word" character, i.e. letters and numbers `\W` matches anything that isn't a "word"

The following code demonstrates the six shortcuts with a selection of letters, numbers and punctuation characters:

```{r}
x <- "abcd ABCD 12345 -!@#%."
# matches any pattern containing at least one digit
str_view(x, "\\d+")
# matches any pattern containing at least one non-digit
str_view(x, "\\D+")

# matches any pattern containing at least one whitespace
str_view(x, "\\s+")
# matches any pattern containing at least one non-whitespace
str_view(x, "\\S+")

# matches any pattern containing at least one letter or number (word)
str_view(x, "\\w+")
# matches any pattern containing at least one non-word
str_view(x, "\\W+")
```

### Quantifiers

**Quantifiers** control how many times a pattern matches. In @sec-pattern-basics you learned about `?` (0 or 1 matches), `+` (1 or more matches), and `*` (0 or more matches). For example `colou?r` will match American or British spelling, `\d+` will match one or more digits, and `\s?` will optionally match a single item of whitespace. You can also specify the number of matches precisely with `{}`:

-   `{n}` matches exactly n times.
-   `{n,}` matches at least n times.
-   `{n,m}` matches between n and m times.

### Operator precedence and parentheses

What does `ab+` match? Any pattern that starts with "a" followed by one or more "b", i.e. any pattern like "ab", "abb", "abbb".

```{r}
str_view(c("a", "ab", "cab", "da", "dabb", "ababb", "a-b"), "ab+")
```

What does `^a|b$` match? Any pattern that starts with "a" or ends with "b".

```{r}
str_view(c("a", "ab", "cab", "da", "dabb", "ababb", "a-b"), "^a|b$")
```

Regular expressions have their own precedence rules: quantifiers have high precedence and alternation has low precedence which means that `ab+` is equivalent to `a(b+)`, and `^a|b$` is equivalent to `(^a)|(b$)`. Just like with algebra, you can use parentheses to override the usual order. But unlike algebra you'll unlikely to remember the precedence rules for regexes, so feel free to use parentheses liberally.

### Grouping and capturing

As well as overriding operator precedence, parentheses have another important effect: they create **capturing groups** that allow you to use sub-components of the match.

The first way to use a capturing group is to refer back to it within a match with **back reference**: `\1` refers to the match contained in the first parenthesis, `\2` in the second parenthesis, and so on. For example, the following pattern finds all fruits that have a repeated pair of letters:

```{r}
str_view(fruit, "(..)\\1")
```

This one finds all words that start and end with the same pair of letters:

```{r}
str_view(words, "^(..).*\\1$")
```

You can also use back references in `str_replace()`. For example, this code switches the order of the second and third words in `sentences`:

```{r}
sentences |>
  str_replace("(\\w+) (\\w+) (\\w+)", "\\1 \\3 \\2") |>
  str_view()
```

If you want to extract the matches for each group you can use `str_match()`. But `str_match()` returns a matrix, so it's not particularly easy to work with:

```{r}
sentences |>
  str_match("the (\\w+) (\\w+)") |>
  head()
```

You could convert to a tibble and name the columns:

```{r}
sentences |>
  str_match("the (\\w+) (\\w+)") |>
  as_tibble(.name_repair = "minimal") |>
  set_names("match", "word1", "word2")
```

But then you've basically recreated your own version of `separate_wider_regex()`. Indeed, behind the scenes, `separate_wider_regex()` converts your vector of patterns to a single regex that uses grouping to capture the named components.

Occasionally, you'll want to use parentheses without creating matching groups. You can create a non-capturing group with `(?:)`

```{r}
x <- c("a grey cat", "a grey dog")
str_match(x, "gr(e|a)y")
str_match(x, "gr(?:e|a)y")
```

### Exercises

1.  How would you match the literal string `"'\`? How about `"$^$"`

    The literal string `"'\` will be written with escape backslashes, i.e. `\"\'\\`. If the matching is done using a regular expression, the regular expression

    -   will write both `"` and `'` with the escape backslash, just like string, hence `"\"\'"` for `"'`,
    -   will write the backslash written 3 additional backslashes in order to escape both the regular expression and the string, hence `"\\\\"` for `\`,

    so the regular expression for `"'\` will be `"\"\'\\\\"`.

    Another way is to use raw string, i.e. `r"(expression)"`, hence `r"("'\)"`.

    The following snippet tests the regular expression and the raw string on a test vector where the first three elements contain the string while the fourth element does not contain it.

    ```{r}
    test_vec <- c("\"\'\\", "bla\"\'\\bla", "\"\'\\ #-\\ $", "\"\'\'")
    str_view(test_vec)
    str_view(test_vec, "\"\'\\\\")
    str_view(test_vec, r"(\"\'\\)")
    ```

    The literal string `"$^$"` will be written with escape backslashes, (only) for `"`, i.e. `"\"$^$\""`. A regular expression, will need to escape `$` and `^`, so both will be written with two backslashes. One other way is to use `[$]` inside the regular expression. Or a raw string.

    ```{r}
    test_vec <- c("\"$^$\"", "bla\"$^$\"bla", "\"$^$\"#-\\ $", "\"$^^$\"")
    str_view(test_vec)
    str_view(test_vec, "\"\\$\\^\\$\"")
    str_view(test_vec, "\"[$]\\^[$]\"")
    str_view(test_vec, r"(\"$^$\")")
    ```

2.  Explain why each of these patterns don't match `\`: `"\"`, `"\\"`, `"\\\"`

    The literal string `\` is written as `"\\"`

    ```{r}
    backslash <- "\\"
    str_view(backslash)
    ```

    -   For the first pattern, `"\"`, the backslash will escape the (second) quotation mark, i.e. `\"` will be interpreted `"`, making the first quotation mark unclosed.

    -   For the second pattern, `"\\"` will resolve to `\` which will escape the next character in the regular expression.

    -   For the third pattern, `"\\\"` the first backslash will escape the second backslash, i.e. the first two backslashes `\\` will be interpreted as `\`, the third backslash will escape the second quotation mark, i.e. the third backslash and the second quotation mark will be interpreted as `"` so the whole patterns `"\\\"` will be interpreted as `"\`, making the first quotation mark unclosed.

3.  Given the corpus of common words in `stringr::words`, create regular expressions that find all words that:

    a.  Start with “y”.

        ```{r}
        str_view(words, "^y")
        ```

    b.  Don’t start with “y”.

        ```{r}
        str_view(words, "^[^y]")
        ```

    c.  End with “x”.

        ```{r}
        str_view(words, "x$")
        ```

    d.  Are exactly three letters long. (Don’t cheat by using `str_length()`!)

        ```{r}
        str_view(words, "^.{3}$")
        ```

    e.  Have seven letters or more.

        ```{r}
        str_view(words, ".{7,}")
        ```

    f.  Contain a vowel-consonant pair.

        ```{r}
        str_view(words, "[aeiou][^aeiou]")
        ```

    g.  Contain at least two vowel-consonant pairs in a row.

        ```{r}
        str_view(words, "([aeiou][^aeiou])\\1")
        ```

    h.  Only consist of repeated vowel-consonant pairs.

        ```{r}
        str_view(words, "^([aeiou][^aeiou])\\1$")  
        ```

4.  Create 11 regular expressions that match the British or American spellings for each of the following words: airplane/aeroplane, aluminum/aluminium, analog/analogue, ass/arse, center/centre, defense/defence, donut/doughnut, gray/grey, modeling/modelling, skeptic/sceptic, summarize/summarise. Try and make the shortest possible regex!

    ```{r}
    str_view(c("airplane", "aeroplane"), "a(ir|ero)plane")

    str_view(c("aluminum", "aluminium"), "alumi(ni?)um")

    str_view(c("analog", "analogue"), "analog(ue)?")

    str_view(c("ass", "arse"), "a(ss|rse)")

    str_view(c("center", "centre"), "cent(er|re)")

    str_view(c("defense", "defence"), "defen(s|c)e")
    str_view(c("defense", "defence"), "defen[sc]e")

    str_view(c("donut", "doughnut"), "do(ugh)?nut")

    str_view(c("gray", "grey"), "gr(a|e)y")
    str_view(c("gray", "grey"), "gr[ae]y")

    str_view(c("modeling", "modelling"), "modell?ing")
    str_view(c("modeling", "modelling"), "model(l?)ing")

    str_view(c("skeptic", "sceptic"), "s(k|c)eptic")
    str_view(c("skeptic", "sceptic"), "s[kc]eptic")

    str_view(c("summarize", "summarise"), "summari(z|s)e")
    str_view(c("summarize", "summarise"), "summari[zs]e")
    ```

5.  Switch the first and last letters in `words`. Which of those strings are still `words`?

    Grouping and capturing can be used in order to capture the first and last letters and then switch them. Checking which strings are still `words` can be done by using `instersect`, over the original `words` vector and the switched one.

    ```{r}
    words_switched <- str_replace_all(
      words,
      "^(.)(.*)(.)$", 
      c("\\3\\2\\1")
      )
    intersect(words_switched, words)
    ```

6.  Describe in words what these regular expressions match: (read carefully to see if each entry is a regular expression or a string that defines a regular expression.)

    a.  `^.*$`

        The entry is a regular expression. The string that defines it is simply "\^.\*\$". It will select any string that starts with any character except newline and it will stop at the end of the entry, except the case where the entry ends with a newline in which case will select the last non-newline character.

        ```{r}
        test <- c("ab", "\nab", "a\nb", "ab\n", "a\nb\n", "\n", "\n\n", "\t")
        str_view(test)
        reg_exp <- "^.*$"
        str_view(test, reg_exp)
        ```

    b.  `"\\{.+\\}"`

        The entry is a string that defines a regular expression. It will select any text between curly bracklets, that contain any text, except the cases where there is no character between them and when they contain a newline character.

        ```{r}
        test <- c("{}", "{a}", "{ab}", "{abc}", "{ab\nc}", "a{ab}c")
        str_view(test)
        reg_exp <- "\\{.+\\}"
        str_view(test, reg_exp)
        ```

    c.  `\d{4}-\d{2}-\d{2}`

        The entry is a regular expression. It will select phone numbers in the format `xxxx-xx-xx`, where `x` are numbers.

        ```{r}
        test <- c("2222-34-12", "222a-34-12" ,"114-00-92", "1-3-44", "1a-22-22", "112-23-45", "1145-32-134", "1467-32-63a662")
        str_view(test)
        reg_exp <- "\\d{4}-\\d{2}-\\d{2}"
        str_view(test, reg_exp)
        ```

    d.  `"\\\\{4}"`

        The entry is a string defining a regular expression. It will select series of 4 consecutive backslashes

        ```{r}
        test <- c("a\\\\\\\\ef\\\\\\f\\\\", "\\\\\\" , "\\\\\\\\\\" , "\\\\\\\\-\\\\-\\\\\\\\")
        str_view(test)
        reg_exp <- "\\\\{4}"
        str_view(test, reg_exp)
        ```

    e.  `\..\..\..`

        The entry is a regular expression. It selects formats `.x.x.x` where `x` can be any character except newlines.

        ```{r}
        test <- c(".x.y.z", ".a.b.\t" , "ab.c.d.ef", "a.bc.d.ef", "a.\n.b.cd")
        str_view(test)
        reg_exp <- "\\..\\..\\.."
        str_view(test, reg_exp)
        ```

    f.  `(.)\1\1`

        The entry is a regular expression. It selects any series formed by 3 identical characters except newlines.

        ```{r}
        test <- c("abbbcddefffg", "aaaa" , "ab\t\t\tc", "a\n\n\nb")
        str_view(test)
        reg_exp <- "(.)\\1\\1"
        str_view(test, reg_exp)
        ```

    g.  `"(..)\\1"`

        The entry is a string defining a regular expression. It selects any series formed by 2 identical two-characters length bits, except newlines.

        ```{r}
        test <- c("aaa", "ababc", "aaaabd" ,"ab\t\tc", "ab\t\b\t\bc", "arwrwdb")
        str_view(test)
        reg_exp <- "(..)\\1"
        str_view(test, reg_exp)
        ```

7.  Solve the beginner regexp crosswords at <https://regexcrossword.com/challenges/beginner>.

## Patern control

It's possible to exercise extra control over the details of the match by using a pattern object instead of just a string. This allows you to control the so called regex flags and match various types of fixed strings, as described bellow.

### Regex flags

There are a number of settings that can be used to control the details of the regexp. These settings are often called **flags** in other programming languages. In stringr, you can use these by wrapping the pattern in a call to `regex()`. The most useful flag is probably `ignore_case = TRUE` because it allows characters to match either their uppercase or lowercase forms:

```{r}
bananas <- c("banana", "Banana", "BANANA")
str_view(bananas, "banana")
str_view(bananas, regex("banana", ignore_case = TRUE))
```

If you're doing a lot of work with multiline strings (i.e. strings that contain `\n`) `dotall` and `multiline` may also be useful:

-   `dotall = TRUE` lets `.` match everything, including `\n`:

    ```{r}
    x <-"Line 1\nLine 2\nLine 3"
    str_view(x, ".Line")
    str_view(x, regex(".Line", dotall = TRUE))
    ```

-   `multiline = TRUE` makes `^` and `$` match the start and end of each line rather than the start and end of the complete string:

    ```{r}
    x <-"Line 1\nLine 2\nLine 3"
    str_view(x, "^Line")
    str_view(x, regex("^Line", multiline = TRUE))
    ```

Finally, if you're writing a complicated regular expression and you're worried you might not understand it in the future, you might try `comments = TRUE`. It tweaks the pattern language to ignore spaces and new lines, as well as everything after `#`. This allows you to use comments and whitespaces to make complex regular expressions more understandable, as in the following example:

```{r}
phone <- regex(
  r"(
    \(?     # optional opening parens
    (\d{3}) # area code
    [)\-]?  # optional closing parens or dash
    \ ?     # optional space
    (\d{3}) # another three numbers
    [\ -]?  # optional space or dash
    (\d{4}) # four more numbers
  )",
  comments = TRUE
)

str_extract(c("514-791-8141", "(123) 456 7890", "123456"), phone)
```

If you're using comments and want to match a space, newline, or `#`, you'll need to escape it with `\`.

### Fixed matches

You can opt-out of the regular expression rules by using `fixed()`:

```{r}
str_view(c("", "a", "."), fixed("."))
```

`fixed()` also gives you the ability to ignore case:

```{r}
str_view("x X", "X")
str_view("x X", fixed("X", ignore_case = TRUE))
```

If you're working with non-English text, you will probably want `coll()` instead of `fixed()`, as it implements the full rules for capitalization as used by the `locale` you specify.

```{r}
str_view("i İ ı I", fixed("İ", ignore_case = TRUE))
str_view("i İ ı I", coll("İ", ignore_case = TRUE, locale = "tr"))
```

## Practice

To put these ideas into practice we’ll solve a few semi-authentic problems next. We’ll discuss three general techniques:

1.  checking your work by creating simple positive and negative controls
2.  combining regular expressions with Boolean algebra
3.  creating complex patterns using string manipulation

### Check your work

First, let's find all sentences that start with "The". Using the `^`anchor alone is not enough:

```{r}
str_view(sentences, "^The")
```

Because the pattern also matches sentences starting with words like `They` or `These`. We need to make sure that the `e` is the last letter in the word, which we can do by adding a word boundary:

```{r}
str_view(sentences, "^The\\b")
```

What about finding all sentences that begin with a pronoun?

```{r}
str_view(sentences, "^She|He|It|They\\b")
```

A quick inspection of the results shows that we're getting some spurious matches. That's because we forgot to use parentheses:

```{r}
str_view(sentences, "^(She|He|It|They)\\b")
```

You might wonder how you might spot such a mistake if it didn't occur in the first few matches. A good technique is to create a few positive and negative matches and use them to test that your patterns works as expected:

```{r}
pos <- c("He is a boy", "She had a good time")
neg <- c("Shells come from the sea", "Hadley said 'It's a great day'")

pattern <- "^(She|He|It|They)\\b"
str_detect(pos, pattern)
str_detect(neg, pattern)
```

### Boolean operations

Imagine we want to find words that only contain consonants. One technique is to create a character class that contains all letters except for the vowels `([^aeiou]`), then allow that to match any number of letters `([^aeiou]+`), then force it to match the whole string by anchoring to the beginning and the end `(^[^aeiou]+$`):

```{r}
str_view(words, "^[^aeiou]+$")
```

You can make this problem a bit easier by flipping the problem around. Instead of looking for words that contain only consonants, we could look for words that don't contain any vowel:

```{r}
str_view(words[!str_detect(words, "[aeiou]")])
```

This is a useful technique whenever you're dealing with logical combinations, particularly those involving "and" or "not". For example, imagine if you want to find all words that contain "a" and "b". There's no "and" operator built in to regular expressions so we have to tackle it by looking for all words that contain an "a" followed by a "b", or a "b" followed by an "a":

```{r}
str_view(words, "a.*b|b.*a")
```

It’s simpler to combine the results of two calls to `str_detect()`:

```{r}
words[str_detect(words, "a") & str_detect(words, "b")]
```

What if we wanted to see if there was a word that contains all vowels? If we did it with patterns we'd need to generate 5! (120) different patterns:

```{r}
#| eval: false
words[str_detect(words, "a.*e.*i.*o.*u")]
# ...
words[str_detect(words, "u.*o.*i.*e.*a")]
```

It's much easier tom combine five calls to `str_detect()`:

```{r}
words[
  str_detect(words, "a") &
  str_detect(words, "e") &
  str_detect(words, "i") &
  str_detect(words, "o") &
  str_detect(words, "u")
]
```

### Creating a patterns with code

What if we wanted to find all sentences that mention a color? The basic idea is simple: we just combine alternation with word boundaries.

```{r}
str_view(sentences, "\\b(red|green|blue)\\b")
```

But as the number of colors grows, it would quickly get tedious to construct this pattern by hand. We can store the colors in a vector and create the patterns from the vector using `str_c()` and `str_flatten()`:

```{r}
rgb <- c("red", "green", "blue")
str_c("\\b(", str_flatten(rgb, "|"), ")\\b")
```

We could make this pattern more comprehensive if we had a good list of colors. One place we could start from is the list of built-in colors that R can use for plots:

```{r}
str_view(colors())
```

Let's first eliminate numbered variants:

```{r}
cols <- colors()
cols <- cols[!str_detect(cols, "\\d")]
str_view(cols)
```

Then we can turn this into a pattern:

```{r}
pattern <- str_c("\\b(", str_flatten(cols, "|"), ")\\b")
str_view(sentences, pattern)
```

In this example, `cols` only contains numbers and letters so you don't need to worry about metacharacters. But in general, whenever you create patterns from existing strings it's wise to run them through `str_escape()` to ensure they match literally.

### Exercises

1.  For each of the following challenges, try solving it by using both a single regular expression, and a combination of multiple `str_detect()` calls.

    a.  Find all `words` that start or end with `x`.

        ```{r}
        # using regular expressions
        str_view(words, "^x|x$")
        # using boolean operation via str_detect
        words[str_detect(words, "^x") | str_detect(words, "x$")]
        ```

    b.  Find all `words` that start with a vowel and end with a consonant.

        ```{r}
        # using regular expressions
        str_view(words, "^[aeiou](.*)[^aeiou]$")
        # using boolean operation via str_detect
        words[str_detect(words, "^[aeiou]") & str_detect(words, "[^aeiou]$")]
        ```

    c.  Are there any `words` that contain at least one of each different vowel?

        ```{r}
        words[
          str_detect(words, "a") &
          str_detect(words, "e") &
          str_detect(words, "i") &
          str_detect(words, "o") &
          str_detect(words, "u")
        ]
        ```

    There are no entries in `words` vectors corresponding to words containing at least one of each different vowels.

2.  Construct patterns to find evidence for and against the rule “i before e except after c”?

    The rule "i before e except after c" implies that that the correct order between (ei) and (ie) is (ie) unless the preceding letter is (c), in which case it may be (ei). To test this rule we look for counterexamples, i.e. for words that contain (ie) after (c), so words that contain (cie) and words that contain (ei) followed by any other letter except c, so words that contain (ei\[\^c\]):

    ```{r}
    str_view(words, "cie|ei[^c]")
    ```

    There are entries in `words` that actually contain (ie) after (c) (science, society) and there are words that contain (ei) followed by any other letter except c (eight, either, receive, weigh).

3.  `colors()` contains a number of modifiers like “lightgray” and “darkblue”. How could you automatically identify these modifiers? (Think about how you might detect and then remove the colors that are modified).

    ```{r}
    basecols <- c("aquamarine", "azure", "beige", "blue", "black", 
                  "brown", "chartreuse", "chocolate", "coral", "cyan",
                  "gold", "goldenrod","gray", "green", "greenyellow",
                  "grey", "honeydew", "ivory", "khaki", "lavender",
                  "linen", "magenta", "maroon", "mistyrose", "navy",
                  "orange", "orchid", "peru", "pink", "plum", "purple",
                  "red", "salmon", "sienna", "snow", "tan", "tomato",
                  "turquoise", "violet", "violetred", "wheat", "white",
                  "yellow")

    cols <- colors()
    cols <- cols[!str_detect(cols, "\\d")]

    modifiers <- str_remove(cols, str_flatten(basecols, "|"))
    unique(modifiers[str_length(modifiers) > 1])
    ```

4.  Create a regular expression that finds any base R dataset. You can get a list of these datasets via a special use of the `data()` function: `data(package = "datasets")$results[, "Item"]`. Note that a number of old datasets are individual vectors; these contain the name of the grouping “data frame” in parentheses, so you’ll need to strip those off.

    ```{r}
    base_r_packages <- data(package = "datasets")$results[, "Item"]
    #base_r_packages

    # The parentheses are striped simply selecting everything before 
    # the whitespace 
    base_r_packages <- str_extract(base_r_packages, "^\\S*")
    #base_r_packages

    regex <- str_flatten(base_r_packages, "|")

    test_datasets_names <- c("fake_dataset", "trees", "sleep", "fake_dataset2")
    str_detect(test_datasets_names, regex)
    ```

## Regular expression in other places

Just like in the stringr and tidyr functions, there are many other places in R where you can use regular expressions. The following sections describe some other useful functions in the wider tidyverse and base R.

### `tidyverse`

There are three other particularly useful places where you might want to use a regular expressions:

-   `matches(pattern)` will select all variables whose name matches the supplied pattern. It’s a “tidyselect” function that you can use anywhere in any tidyverse function that selects variables (e.g., `select()`, `rename_with()` and `across()`).

-   `pivot_longer()`'s names_pattern argument takes a vector of regular expressions, just like `separate_wider_regex()`. It’s useful when extracting data out of variable names with a complex structure.

-   The delim argument in `separate_longer_delim()` and `separate_wider_delim()` usually matches a fixed string, but you can use `regex()` to make it match a pattern. This is useful, for example, if you want to match a comma that is optionally followed by a space, i.e. `regex(", ?")`.

### Base R

`apropos(pattern)` searches all objects available from the global environment that match the given pattern. This is useful if you can’t quite remember the name of a function:

```{r}
apropos("replace")
```

`list.files(path, pattern)` lists all files in path that match a regular expression pattern. For example, you can find all the Quarto files in the current directory with:

```{r}
head(list.files(pattern = "\\.qmd$"))
```

## Summary

With every punctuation character potentially overloaded with meaning, regular expressions are one of the most compact languages out there. They’re definitely confusing at first but as you train your eyes to read them and your brain to understand them, you unlock a powerful skill that you can use in R and in many other places.

In this chapter, you’ve started your journey to become a regular expression master by learning the most useful stringr functions and the most important components of the regular expression language. And there are plenty of resources to learn more.

A good place to start is `vignette("regular-expressions", package = "stringr")`: it documents the full set of syntax supported by stringr. Another useful reference is <https://www.regular-expressions.info/>. It’s not R specific, but you can use it to learn about the most advanced features of regexes and how they work under the hood.

It’s also good to know that stringr is implemented on top of the stringi package by Marek Gagolewski. If you’re struggling to find a function that does what you need in stringr, don’t be afraid to look in stringi. You’ll find stringi very easy to pick up because it follows many of the the same conventions as stringr.
